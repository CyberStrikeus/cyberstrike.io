---
title: Custom Providers
description: Configure OpenAI-compatible and custom providers for Cyberstrike
sidebar:
  order: 7
  label: Custom Providers
---

Connect Cyberstrike to any OpenAI-compatible API endpoint or custom provider.

{/* TODO: Screenshot - Custom provider configuration */}
<div className="border-2 border-dashed border-gray-400 dark:border-gray-600 rounded-lg p-8 my-6 text-center bg-gray-100 dark:bg-gray-800">
  <p className="text-gray-500 dark:text-gray-400 font-mono text-sm">ðŸ“¸ SCREENSHOT: custom-provider-config.png</p>
  <p className="text-gray-400 dark:text-gray-500 text-xs mt-2">Custom provider configuration</p>
</div>

## OpenAI-Compatible APIs

Many services provide OpenAI-compatible endpoints:

| Service | Base URL |
|---------|----------|
| Together AI | https://api.together.xyz/v1 |
| Anyscale | https://api.endpoints.anyscale.com/v1 |
| Fireworks | https://api.fireworks.ai/inference/v1 |
| Groq | https://api.groq.com/openai/v1 |
| DeepInfra | https://api.deepinfra.com/v1/openai |
| Perplexity | https://api.perplexity.ai |

## Basic Configuration

### Generic OpenAI-Compatible

```json title="~/.cyberstrike/config.json"
{
  "provider": {
    "openai-compatible": {
      "name": "Custom Provider",
      "options": {
        "baseURL": "https://api.example.com/v1",
        "apiKey": "{env:CUSTOM_API_KEY}"
      }
    }
  }
}
```

### Command Line

```bash
cyberstrike --model openai-compatible/model-name
```

## Provider Examples

### Groq

Fast inference with Groq:

```json title="~/.cyberstrike/config.json"
{
  "provider": {
    "groq": {
      "name": "Groq",
      "options": {
        "baseURL": "https://api.groq.com/openai/v1",
        "apiKey": "{env:GROQ_API_KEY}"
      }
    }
  },
  "model": "groq/llama-3.3-70b-versatile"
}
```

Available models:
- llama-3.3-70b-versatile
- llama-3.1-8b-instant
- mixtral-8x7b-32768

### Together AI

```json
{
  "provider": {
    "together": {
      "name": "Together AI",
      "options": {
        "baseURL": "https://api.together.xyz/v1",
        "apiKey": "{env:TOGETHER_API_KEY}"
      }
    }
  },
  "model": "together/meta-llama/Llama-3.3-70B-Instruct-Turbo"
}
```

### Fireworks AI

```json
{
  "provider": {
    "fireworks": {
      "name": "Fireworks",
      "options": {
        "baseURL": "https://api.fireworks.ai/inference/v1",
        "apiKey": "{env:FIREWORKS_API_KEY}"
      }
    }
  },
  "model": "fireworks/accounts/fireworks/models/llama-v3p3-70b-instruct"
}
```

### DeepInfra

```json
{
  "provider": {
    "deepinfra": {
      "name": "DeepInfra",
      "options": {
        "baseURL": "https://api.deepinfra.com/v1/openai",
        "apiKey": "{env:DEEPINFRA_API_KEY}"
      }
    }
  },
  "model": "deepinfra/meta-llama/Llama-3.3-70B-Instruct"
}
```

## OpenRouter

Access multiple providers through OpenRouter:

```json title="~/.cyberstrike/config.json"
{
  "provider": {
    "openrouter": {
      "options": {
        "apiKey": "{env:OPENROUTER_API_KEY}"
      }
    }
  },
  "model": "openrouter/anthropic/claude-sonnet-4"
}
```

### Available Models

OpenRouter provides access to:
- Anthropic (Claude)
- OpenAI (GPT-4)
- Google (Gemini)
- Meta (Llama)
- Mistral
- And many more

### Model Selection

```bash
cyberstrike --model openrouter/openai/gpt-4o
cyberstrike --model openrouter/anthropic/claude-sonnet-4
cyberstrike --model openrouter/google/gemini-pro
```

## Self-Hosted Solutions

### vLLM

```json
{
  "provider": {
    "vllm": {
      "name": "vLLM Server",
      "options": {
        "baseURL": "http://localhost:8000/v1",
        "apiKey": "dummy"
      }
    }
  }
}
```

Start vLLM:

```bash
python -m vllm.entrypoints.openai.api_server \
  --model meta-llama/Llama-3.3-70B-Instruct \
  --port 8000
```

### Text Generation WebUI

```json
{
  "provider": {
    "textgen": {
      "name": "Text Generation WebUI",
      "options": {
        "baseURL": "http://localhost:5000/v1",
        "apiKey": "dummy"
      }
    }
  }
}
```

### LM Studio

```json
{
  "provider": {
    "lmstudio": {
      "name": "LM Studio",
      "options": {
        "baseURL": "http://localhost:1234/v1",
        "apiKey": "lm-studio"
      }
    }
  }
}
```

## Azure OpenAI

```json title="~/.cyberstrike/config.json"
{
  "provider": {
    "azure": {
      "name": "Azure OpenAI",
      "options": {
        "baseURL": "https://your-resource.openai.azure.com/openai/deployments/your-deployment",
        "apiKey": "{env:AZURE_API_KEY}",
        "apiVersion": "2024-02-15-preview"
      }
    }
  }
}
```

### Environment Variables

```bash
export AZURE_API_KEY="..."
export AZURE_RESOURCE_NAME="your-resource"
export AZURE_DEPLOYMENT_NAME="your-deployment"
```

## Advanced Configuration

### Custom Headers

```json
{
  "provider": {
    "custom": {
      "options": {
        "baseURL": "https://api.example.com/v1",
        "apiKey": "your-key",
        "headers": {
          "X-Custom-Header": "value"
        }
      }
    }
  }
}
```

### Timeout and Retries

```json
{
  "provider": {
    "custom": {
      "options": {
        "baseURL": "https://api.example.com/v1",
        "timeout": 120000,
        "maxRetries": 3
      }
    }
  }
}
```

### Proxy Configuration

```json
{
  "provider": {
    "custom": {
      "options": {
        "baseURL": "https://api.example.com/v1",
        "httpAgent": {
          "proxy": "http://proxy.example.com:8080"
        }
      }
    }
  }
}
```

## Model Mapping

Map custom model names:

```json
{
  "provider": {
    "custom": {
      "options": {
        "baseURL": "https://api.example.com/v1",
        "modelMapping": {
          "gpt-4": "custom-gpt-4-equivalent",
          "claude-sonnet": "custom-claude-equivalent"
        }
      }
    }
  }
}
```

## Testing Custom Providers

### Verify Connection

```bash
cyberstrike --model custom/model-name
```

### Test Message

```
> Hello, can you confirm you're working?
```

### Check Model List

Some providers support listing models:

```bash
curl https://api.example.com/v1/models \
  -H "Authorization: Bearer $API_KEY"
```

## Troubleshooting

### Authentication Failed

```
Error: 401 Unauthorized
```

Verify:
- API key is correct
- Key has required permissions
- Authorization header format

### Model Not Found

```
Error: Model not found
```

Check:
- Model ID matches provider's format
- Model is available on the provider
- Correct provider is selected

### Connection Timeout

```
Error: Request timeout
```

Solutions:
- Increase timeout value
- Check network connectivity
- Verify base URL is correct

### Invalid Response Format

```
Error: Unexpected response format
```

The provider may not be fully OpenAI-compatible. Check:
- API documentation
- Response structure
- Required headers

<Aside variant="caution">
  Not all OpenAI-compatible APIs support all features. Tool calling and streaming may vary by provider.
</Aside>

## Related Documentation

- [Providers Overview](/docs/providers) - All providers
- [Ollama](/docs/providers/ollama) - Local models
- [Configuration](/docs/configuration) - Full options
