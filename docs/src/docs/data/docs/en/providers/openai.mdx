---
title: OpenAI (GPT)
description: Configure OpenAI models for Cyberstrike
sidebar:
  order: 3
  label: OpenAI
---

OpenAI provides GPT-4 and o1 models for security analysis. This guide covers setup and configuration.

{/* TODO: Screenshot - OpenAI model selection */}
<div className="border-2 border-dashed border-gray-400 dark:border-gray-600 rounded-lg p-8 my-6 text-center bg-gray-100 dark:bg-gray-800">
  <p className="text-gray-500 dark:text-gray-400 font-mono text-sm">ðŸ“¸ SCREENSHOT: openai-model-select.png</p>
  <p className="text-gray-400 dark:text-gray-500 text-xs mt-2">OpenAI model selection dialog</p>
</div>

## Available Models

| Model | Context | Best For |
|-------|---------|----------|
| gpt-4o | 128K | General security testing |
| gpt-4o-mini | 128K | Quick tasks, high volume |
| o1 | 128K | Complex reasoning |
| o1-mini | 128K | Faster reasoning tasks |
| gpt-4-turbo | 128K | Balanced performance |

## Authentication

### API Key Setup

1. Get your API key from [platform.openai.com](https://platform.openai.com)
2. Run authentication:

```bash
cyberstrike auth login
# Select: OpenAI
# Enter your API key
```

### Environment Variable

```bash
export OPENAI_API_KEY="sk-proj-..."
```

### Configuration File

```json title="~/.cyberstrike/config.json"
{
  "provider": {
    "openai": {
      "options": {
        "apiKey": "{env:OPENAI_API_KEY}"
      }
    }
  }
}
```

## Model Configuration

### Set Default Model

```json title="~/.cyberstrike/config.json"
{
  "model": "openai/gpt-4o"
}
```

### Command Line Override

```bash
cyberstrike --model openai/o1
```

### Using o1 Reasoning Models

o1 models excel at complex security analysis:

```bash
cyberstrike --model openai/o1
```

Best for:
- Complex vulnerability chains
- Attack path analysis
- Cryptographic analysis
- Reverse engineering

## ChatGPT Plus/Pro

Use your ChatGPT subscription:

```bash
cyberstrike auth login
# Select: OpenAI
# Choose: ChatGPT Plus/Pro
# Complete browser authentication
```

<Aside variant="info">
  ChatGPT authentication requires browser-based OAuth flow.
</Aside>

## Organization ID

For organization accounts:

```json title="~/.cyberstrike/config.json"
{
  "provider": {
    "openai": {
      "options": {
        "apiKey": "{env:OPENAI_API_KEY}",
        "organization": "org-..."
      }
    }
  }
}
```

## Custom Base URL

For OpenAI-compatible endpoints:

```json
{
  "provider": {
    "openai": {
      "options": {
        "baseURL": "https://your-endpoint.com/v1"
      }
    }
  }
}
```

## Function Calling

GPT models support function calling for tool use:

```json
{
  "provider": {
    "openai": {
      "options": {
        "parallelToolCalls": true
      }
    }
  }
}
```

## Rate Limits

OpenAI rate limits by tier:

| Tier | RPM | TPM |
|------|-----|-----|
| Free | 3 | 40,000 |
| Tier 1 | 500 | 200,000 |
| Tier 2 | 5,000 | 2,000,000 |
| Tier 3+ | Higher limits |

### Handling Limits

```json
{
  "provider": {
    "openai": {
      "options": {
        "maxRetries": 3,
        "timeout": 60000
      }
    }
  }
}
```

## Best Practices

### Model Selection

| Task | Recommended Model |
|------|-------------------|
| Quick scans | gpt-4o-mini |
| General testing | gpt-4o |
| Complex analysis | o1 |
| Cost-sensitive | gpt-4o-mini |

### Cost Optimization

1. Use mini models for simple tasks
2. Set reasonable max tokens
3. Use `/compact` for long sessions
4. Monitor usage on OpenAI dashboard

### Security

1. Store keys in environment variables
2. Use project-specific API keys
3. Enable usage limits in OpenAI dashboard
4. Rotate keys periodically

## Troubleshooting

### Invalid API Key

```
Error: Incorrect API key provided
```

Verify:
- Key starts with `sk-proj-` or `sk-`
- No extra whitespace
- Key is active

### Insufficient Quota

```
Error: You exceeded your current quota
```

Solutions:
- Add billing information
- Check usage limits
- Upgrade your plan

### Model Access

```
Error: The model does not exist or you do not have access
```

Some models require:
- Tier 3+ for o1
- Waitlist approval
- Enterprise agreement

<Aside variant="caution">
  o1 models have higher latency due to reasoning steps. Plan for longer response times.
</Aside>

## Related Documentation

- [Providers Overview](/docs/providers) - All providers
- [Custom Providers](/docs/providers/custom-providers) - OpenAI-compatible setup
- [Configuration](/docs/configuration) - Full options
