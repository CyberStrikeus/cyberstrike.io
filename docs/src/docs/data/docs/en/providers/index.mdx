---
title: AI Providers
description: Configure and use different AI providers with Cyberstrike
sidebar:
  order: 1
  label: Overview
---

Cyberstrike supports multiple AI providers, giving you flexibility in choosing the best model for your security assessments.

{/* TODO: Screenshot - Provider selection dialog */}
<div className="border-2 border-dashed border-gray-400 dark:border-gray-600 rounded-lg p-8 my-6 text-center bg-gray-100 dark:bg-gray-800">
  <p className="text-gray-500 dark:text-gray-400 font-mono text-sm">ðŸ“¸ SCREENSHOT: s05-provider-dialog.png</p>
  <p className="text-gray-400 dark:text-gray-500 text-xs mt-2">Provider seÃ§im dialogu</p>
</div>

{/* TODO: Diagram - Provider selection flow */}
<div className="border-2 border-dashed border-gray-400 dark:border-gray-600 rounded-lg p-8 my-6 text-center bg-gray-100 dark:bg-gray-800">
  <p className="text-gray-500 dark:text-gray-400 font-mono text-sm">ðŸ“Š DIAGRAM: provider-selection-flow.mermaid</p>
  <p className="text-gray-400 dark:text-gray-500 text-xs mt-2">Provider seÃ§im akÄ±ÅŸ diyagramÄ±</p>
</div>

## Supported Providers

| Provider | Models | Best For |
|----------|--------|----------|
| **Anthropic** | Claude Opus 4.5, Sonnet 4, Haiku | Complex reasoning, long context |
| **OpenAI** | GPT-4o, o1, o1-preview | General purpose, fast responses |
| **Google** | Gemini 2.0 Flash, Pro | Multimodal, large context |
| **AWS Bedrock** | Claude, Llama, Titan | Enterprise, on-prem |
| **Azure OpenAI** | GPT-4, GPT-4o | Enterprise compliance |
| **Google Vertex AI** | Gemini, Claude | Enterprise GCP |
| **OpenRouter** | Many models | Free tier, model variety |
| **Groq** | Llama 3.3, Mixtral | Speed, cost efficiency |
| **Ollama** | Local models | Privacy, offline use |

## Adding Credentials

### Interactive Login

```bash
cyberstrike auth login
```

Select your provider and enter your API key.

### Environment Variables

Set API keys in your environment:

```bash
# Anthropic
export ANTHROPIC_API_KEY="sk-ant-..."

# OpenAI
export OPENAI_API_KEY="sk-..."

# Google
export GOOGLE_API_KEY="AI..."

# OpenRouter
export OPENROUTER_API_KEY="sk-or-..."

# Groq
export GROQ_API_KEY="gsk_..."
```

Add to your shell profile (`~/.bashrc` or `~/.zshrc`) for persistence.

### Configuration File

Store credentials in `~/.cyberstrike/config.json`:

```json
{
  "provider": {
    "anthropic": {
      "options": {
        "apiKey": "{env:ANTHROPIC_API_KEY}"
      }
    }
  }
}
```

---

## Anthropic

Claude models are recommended for complex security analysis.

### Authentication

```bash
cyberstrike auth login
# Select: Anthropic
# Enter API key from console.anthropic.com
```

Or via environment:

```bash
export ANTHROPIC_API_KEY="sk-ant-..."
```

### Available Models

| Model | ID | Context | Best For |
|-------|-----|---------|----------|
| Claude Opus 4.5 | `claude-opus-4-5-20250514` | 200K | Complex analysis |
| Claude Sonnet 4 | `claude-sonnet-4-20250514` | 200K | Balanced performance |
| Claude Haiku 4.5 | `claude-haiku-4-5-20250514` | 200K | Quick tasks |

### Usage

```bash
# Via command line
cyberstrike --model anthropic/claude-sonnet-4-20250514

# Via config
{
  "model": "anthropic/claude-sonnet-4-20250514"
}
```

### Configuration Options

```json
{
  "provider": {
    "anthropic": {
      "options": {
        "apiKey": "{env:ANTHROPIC_API_KEY}",
        "timeout": 300000
      }
    }
  }
}
```

---

## OpenAI

GPT-4 models provide fast, reliable responses.

### Authentication

```bash
cyberstrike auth login
# Select: OpenAI
# Enter API key from platform.openai.com
```

Or via environment:

```bash
export OPENAI_API_KEY="sk-..."
```

### Available Models

| Model | ID | Context | Best For |
|-------|-----|---------|----------|
| GPT-4o | `gpt-4o` | 128K | General purpose |
| GPT-4o Mini | `gpt-4o-mini` | 128K | Cost efficiency |
| o1 | `o1` | 200K | Complex reasoning |
| o1 Preview | `o1-preview` | 128K | Advanced tasks |

### Usage

```bash
cyberstrike --model openai/gpt-4o
```

### Configuration Options

```json
{
  "provider": {
    "openai": {
      "options": {
        "apiKey": "{env:OPENAI_API_KEY}",
        "baseURL": "https://api.openai.com/v1"
      }
    }
  }
}
```

---

## Google

Gemini models excel at multimodal tasks.

### Authentication

```bash
export GOOGLE_API_KEY="AI..."
```

Or via Google Cloud:

```bash
gcloud auth application-default login
```

### Available Models

| Model | ID | Context | Best For |
|-------|-----|---------|----------|
| Gemini 2.0 Flash | `gemini-2.0-flash-exp` | 1M | Fast, experimental |
| Gemini 1.5 Pro | `gemini-1.5-pro` | 2M | Large context |
| Gemini 1.5 Flash | `gemini-1.5-flash` | 1M | Speed |

### Usage

```bash
cyberstrike --model google/gemini-2.0-flash-exp
```

---

## OpenRouter

Access many models through a single API with a free tier.

### Authentication

```bash
cyberstrike auth login
# Select: OpenRouter
# Get API key from openrouter.ai/keys
```

Or via environment:

```bash
export OPENROUTER_API_KEY="sk-or-..."
```

### Free Tier Models

| Model | ID |
|-------|-----|
| Llama 4 Scout | `meta-llama/llama-4-scout:free` |
| Gemini 2.0 Flash | `google/gemini-2.0-flash-exp:free` |
| Mistral Small | `mistralai/mistral-small-3.2-24b-instruct:free` |

### Usage

```bash
cyberstrike --model openrouter/meta-llama/llama-4-scout:free
```

### Configuration

```json
{
  "model": "openrouter/meta-llama/llama-4-scout:free",
  "provider": {
    "openrouter": {
      "options": {
        "apiKey": "{env:OPENROUTER_API_KEY}"
      }
    }
  }
}
```

---

## AWS Bedrock

Use Claude and other models through AWS.

### Authentication

Configure AWS credentials:

```bash
# Via AWS CLI
aws configure

# Or via environment
export AWS_ACCESS_KEY_ID="..."
export AWS_SECRET_ACCESS_KEY="..."
export AWS_REGION="us-east-1"
```

### Available Models

| Model | ID |
|-------|-----|
| Claude Sonnet | `anthropic.claude-sonnet-4-20250514-v1:0` |
| Claude Haiku | `anthropic.claude-haiku-4-5-20250514-v1:0` |
| Llama 3.3 | `meta.llama3-3-70b-instruct-v1:0` |

### Configuration

```json
{
  "model": "amazon-bedrock/anthropic.claude-sonnet-4-20250514-v1:0",
  "provider": {
    "amazon-bedrock": {
      "options": {
        "region": "us-east-1"
      }
    }
  }
}
```

---

## Azure OpenAI

Enterprise Azure deployment of OpenAI models.

### Authentication

```bash
export AZURE_API_KEY="..."
export AZURE_RESOURCE_NAME="your-resource"
```

### Configuration

```json
{
  "provider": {
    "azure": {
      "options": {
        "apiKey": "{env:AZURE_API_KEY}",
        "resourceName": "your-resource",
        "deploymentId": "gpt-4o"
      }
    }
  }
}
```

---

## Google Vertex AI

Enterprise Google Cloud AI.

### Authentication

```bash
gcloud auth application-default login
```

### Configuration

```json
{
  "provider": {
    "google-vertex": {
      "options": {
        "project": "your-project-id",
        "location": "us-central1"
      }
    }
  }
}
```

---

## Ollama (Local)

Run models locally for privacy and offline use.

### Setup

1. Install Ollama:

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

2. Pull a model:

```bash
ollama pull llama3.3
```

3. Start Ollama:

```bash
ollama serve
```

### Usage

```bash
# No API key needed
cyberstrike --model ollama/llama3.3
```

### Available Models

| Model | Pull Command |
|-------|-------------|
| Llama 3.3 | `ollama pull llama3.3` |
| CodeLlama | `ollama pull codellama` |
| Mistral | `ollama pull mistral` |
| Qwen | `ollama pull qwen2.5` |

### Configuration

```json
{
  "model": "ollama/llama3.3",
  "provider": {
    "ollama": {
      "options": {
        "baseURL": "http://localhost:11434"
      }
    }
  }
}
```

---

## Groq

Fastest inference for supported models.

### Authentication

```bash
export GROQ_API_KEY="gsk_..."
```

### Available Models

| Model | ID |
|-------|-----|
| Llama 3.3 70B | `llama-3.3-70b-versatile` |
| Mixtral 8x7B | `mixtral-8x7b-32768` |

### Usage

```bash
cyberstrike --model groq/llama-3.3-70b-versatile
```

---

## Custom OpenAI-Compatible

Connect to any OpenAI-compatible API.

### Configuration

```json
{
  "provider": {
    "custom-api": {
      "id": "custom-api",
      "name": "Custom API",
      "options": {
        "baseURL": "https://api.custom.example.com/v1",
        "apiKey": "{env:CUSTOM_API_KEY}"
      },
      "models": {
        "custom-model": {
          "name": "Custom Model",
          "contextLength": 32000
        }
      }
    }
  }
}
```

### Usage

```bash
cyberstrike --model custom-api/custom-model
```

---

## Provider Selection Tips

### For Complex Security Analysis

Use Claude Opus 4.5 or Sonnet 4:

```json
{
  "model": "anthropic/claude-opus-4-5-20250514"
}
```

### For Cost Efficiency

Use OpenRouter free tier or Groq:

```json
{
  "model": "openrouter/meta-llama/llama-4-scout:free"
}
```

### For Privacy

Use Ollama with local models:

```json
{
  "model": "ollama/llama3.3"
}
```

### For Enterprise

Use AWS Bedrock or Azure OpenAI with your organization's credentials.

---

## Listing Credentials

View stored credentials:

```bash
cyberstrike auth list
```

Output:

```
Credentials ~/.cyberstrike/auth.json
  Anthropic api
  OpenRouter api

Environment
  ANTHROPIC_API_KEY
```

## Removing Credentials

```bash
cyberstrike auth logout
# Select provider to remove
```

<Aside variant="tip">
  For penetration testing tasks requiring complex reasoning, we recommend **Claude Opus 4.5** or **Claude Sonnet 4**.
</Aside>
